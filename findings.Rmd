---
title: "Findings"
author: "Dan Johnson"
date: "2/22/2018"
output: html_document
bibliography: library.bib
biblio-style: apalike
---
```{r, child="_setup.Rmd"}
```

##Classifier Accuracy
The tables below show observed frequencies for 9,340 TA comments coded by hand, and frequencies for the same TA comments categorized using the optimized Naive Bayes classifier **without** pre-screening. The far right columns are overall subject frequencies, the bottom rows, overall structure frequencies.   

####\  

![*Comparison of frequency tables generated by hand-coding TA comments (top) versus predicted categories using optimized NB classifier (bottom). *](/Users/danjohnson/Dropbox/Coding_Tools/R_Environment/R_Projects/default_website/images/Result_of_NB_2D_mapping_Feb2019.png)

####\  

On average, the classifier is only 80-90% accurate for one subject sub-category or one specific comment. OVERALL though, the optimized NB classifier estimated relative frequencies of Subject subcategories very well; there was <1.5% difference in fractional frequencies between observed (hand-coded) and computationally assigned Subject sub-categories. 

Overall accuracy was considerably lower for Structure sub-categories. Specifically, the NB classifier over-assigned comments to the "Copy-editing" sub-category, and under-assigned comments to the "Specifics" sub-category. Most incorrectly classified comments belonged to the "Technical" Subject sub-category. This **suggest** there may be specific terms present in comments within this sub-category that are problematic, and warrant further exploration. 

####\  

##Data Story 2

####\

#Tool or Analysis 2

####\

##Data Story 3

####\

##Data Story 4

####\



####\
