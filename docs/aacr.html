<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Automated Feedback on Student Writing</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/journal.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>
<link href="site_libs/font-awesome-5.0.13/css/fa-svg-with-js.css" rel="stylesheet" />
<script src="site_libs/font-awesome-5.0.13/js/fontawesome-all.min.js"></script>
<script src="site_libs/font-awesome-5.0.13/js/fa-v4-shims.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 61px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 66px;
  margin-top: -66px;
}

.section h2 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h3 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h4 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h5 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h6 {
  padding-top: 66px;
  margin-top: -66px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Analyzing TA Comments in R</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="notes.html">
    <span class="fa fa-sticky-note"></span>
     
    Notes
  </a>
</li>
<li>
  <a href="background.html">
    <span class="fa fa-history"></span>
     
    Background
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-search"></span>
     
    Lit Review
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="litreview.html">
        <span class="fa fa-search"></span>
         
        Overview
      </a>
    </li>
    <li>
      <a href="techwriting.html">
        <span class="fa fa-chalkboard"></span>
         
        Teaching Writing
      </a>
    </li>
    <li>
      <a href="futurefaculty.html">
        <span class="fa fa-chalkboard-teacher"></span>
         
        Training Future Faculty
      </a>
    </li>
    <li>
      <a href="aacr.html">
        <span class="fa fa-chart-bar"></span>
         
        Automated Text Analysis
      </a>
    </li>
    <li>
      <a href="Text_Classifier_Models.html">
        <span class="fa fa-sort-amount-down"></span>
         
        Intro to Text Classification
      </a>
    </li>
    <li>
      <a href="Topic_categorization.html">
        <span class="fa fa-code-branch"></span>
         
        Topic Modeling
      </a>
    </li>
    <li>
      <a href="Choosing_classifier.html">
        <span class="fa fa-hand-point-up"></span>
         
        Choosing a Classifier
      </a>
    </li>
    <li>
      <a href="Improving_classifier.html">
        <span class="fa fa-edit"></span>
         
        Evaluating Outcomes
      </a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-puzzle-piece"></span>
     
    The Build
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="build.html">
        <span class="fa fa-puzzle-piece"></span>
         
        Overview
      </a>
    </li>
    <li>
      <a href="docxcommentextraction.html">
        <span class="fa fa-cut"></span>
         
        Comment Extraction
      </a>
    </li>
    <li>
      <a href="codebook.html">
        <span class="fa fa-book"></span>
         
        Classification Codebook
      </a>
    </li>
    <li>
      <a href="dataimport.html">
        <span class="fa fa-sign-in-alt"></span>
         
        About the Dataset
      </a>
    </li>
    <li>
      <a href="initial_exploration.html">
        <span class="fa fa-eye"></span>
         
        Initial Exploration
      </a>
    </li>
    <li>
      <a href="NB_2r2c.html">
        <span class="fa fa-map-marker-alt"></span>
         
        NB Classifier
      </a>
    </li>
    <li>
      <a href="Ensemble_Notes.html">
        <span class="fa fa-archive"></span>
         
        Ensemble Classifier
      </a>
    </li>
  </ul>
</li>
<li>
  <a href="initial_exploration.html">
    <span class="fa fa-question-circle"></span>
     
    Data Exploration
  </a>
</li>
<li>
  <a href="findings.html">
    <span class="fa fa-chart-bar"></span>
     
    Findings
  </a>
</li>
<li>
  <a href="sitemap.html">
    <span class="fa fa-shoe-prints"></span>
     
    Next Steps
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Automated Feedback on Student Writing</h1>
<h4 class="date"><em>Mar 15, 2019</em></h4>

</div>


<p>There is growing need and interest in using automated feedback as part of writing training. This raises important questions that have not yet been adequately answered:</p>
<ul>
<li>Can/do automated feedback systems identify similar issues as live instructors, with similar frequency?</li>
<li>When instructors have access to automated feedback, do they trust it? Do they provide feedback on different issues, focus on higher-order problems, or continue grading as if they had no insights?</li>
<li>Do students respond to automated feedback in the same way as feedback from live instructors?</li>
</ul>
<div id="section" class="section level4">
<h4> </h4>
</div>
<div id="origins-of-automated-feedback" class="section level1">
<h1>Origins of Automated Feedback</h1>
<p>Interest in automated feedback on writing emerged in the mid-1960s. Systems have since progressed from basic spelling checkers to syntax-aware spelling and grammar evaluation. More recently, automated essay scoring (AES) systems emerged that can provide feedback on open-response writing. AES systems use natural language processing and machine learning algorithms to produce a score based on syntactic and lexical patterns and features such as sentence length, word frequency and part of speech <span class="citation">(Shermis et al. 2010, <span class="citation">Balfour (2013)</span>)</span>.</p>
<p>Demand for AES systems has spurred development of several commercial products including Criterion®, WriteToLearn™, Intelligent Essay Assessor™, IntelliMetric®, WriteLab, Inc. and Turnitin Feedback Studio.</p>
<p>AES systems have the advantage of being scalable and are very attractive for large face-to-face courses, and for asynchronous courses like massive open online courses <span class="citation">(Balfour 2013)</span>. Still they are not without drawbacks. First, un-/minimally-supervised AES systems may not score student work consistently. Perelman <span class="citation">(Perelman 2013)</span> highlighted their poor accuracy, using obviously faked texts to demonstrate how easily current AES applications are fooled. Second, it is unclear to what extent students pay attention to automated feedback. One small study <span class="citation">(Heffernan and Otoshi 2015)</span> compared relative impacts of teacher feedback versus technology driven feedback from ETS’ Criterion® tool on 12 Japanese English-foreign- language students’ writing. Results showed automated feedback alone was less effective than feedback from the teacher and Criterion® combined. However, the authors only compared scores on three independent, consecutive writing assignments; they did not compare effects of feedback on draft versus final versions of the same assignment. Also, the authors failed to compare automated feedback alone to teachers’ comments alone.</p>
<p>The degree of authority students attach to both automated and human feedback also is a confounding variable. Anecdotally, most instructors can cite many examples of students ignoring basic spelling and grammar feedback that is standard for word processors like MS. Word. Ruegg <span class="citation">(2015)</span> found that feedback from peer reviewers was not valued as much as teachers’ feedback, even though teachers provided less explicit comments than peer reviewers. Ruegg argued that this is likely because teachers are the ones that ultimately grade the student’s writing.</p>
<p>Despite their limitations, demand remains high for AES systems, and there are ongoing efforts to integrate them into more traditional writing review models <span class="citation">(Balfour 2013)</span>. Constructed response assessments reveal more about student thinking and the persistence of misconceptions than do multiple-choice questions. However they require more analysis on the part of the educator, and so are less likely to be used in large-enrollment courses. Urban-Lurain and colleagues developed automated assessment of constructed response (AACR) as a way to give students constructed response test questions and other work that can be graded automatically <span class="citation">(Kaplan et al. 2014, <span class="citation">Weston et al. (2015)</span>, <span class="citation">Ha, Baldwin, and Nehm (2015)</span>, <span class="citation">Urban-Lurain et al. (2015)</span>, <span class="citation">Ha M. and Nehm (2016)</span>)</span>. AACR uses a robust and scalable platform for scoring open responses to pre-written prompts that probe important disciplinary concepts from biology and biological chemistry. The prompts are administered via online course management systems where students enter responses. Lexical and statistical analyses then predict what expert ratings would be for student responses. Work to date shows that automated analyses can predict expert ratings of students’ work on these topics accurately and with higher inter-rater reliability than a group of trained human graders. The AACR model is growing rapidly to include additonal STEM disicplines and has a national presence (<a href="http://create4stem.msu.edu/project/aacr" class="uri">http://create4stem.msu.edu/project/aacr</a>).</p>
<p>The success of AACR <strong>suggests</strong> that the general lexical analysis principles this project is based on can be applied to the analysis of student writing. However, more research is needed before we can say with any confidence that automated feedback benefits students or their instructors.</p>
<p>Our NSF-sponsored propoosal is exploring whether automated feedback affect how graduate teaching assistants (TAs) grade writing-related activities. Using the text classifier being built for this FLC project, we will determine whether TAs provide students with more feedback focused on higher order thinking, and less on low-level copy editing.</p>
<div id="section-1" class="section level4">
<h4> </h4>
<hr />
<p><em>Work Cited</em></p>
<div id="refs" class="references">
<div id="ref-Balfour2013">
<p>Balfour, S. P. 2013. “Assessing Writing in Moocs: Automated Essay Scoring and Calibrated Peer Review (Tm).” In <em>Research &amp; Practice in Assessment</em>. Vol. 8.</p>
</div>
<div id="ref-Ha2015">
<p>Ha, M., B. C. Baldwin, and R. H. Nehm. 2015. “The Long-Term Impacts of Short-Term Professional Development: Science Teachers and Evolution.” <em>Evolution: Education and Outreach</em> 8 (1). doi:<a href="https://doi.org/10.1186/s12052-015-0040-9">10.1186/s12052-015-0040-9</a>.</p>
</div>
<div id="ref-Ha2016">
<p>Ha, M., and R. H. Nehm. 2016. “Predicting the Accuracy of Computer Scoring of Text: Probabilistic, Multi-Model, and Semantic Similarity Approaches.” Baltimore, MD: NARST.</p>
</div>
<div id="ref-Heffernan2015">
<p>Heffernan, N., and J. Otoshi. 2015. “Comparing the Pedagogical Benefits of Both Criterion and Teacher Feedback on Japanese Efl Students’ Writing.” <em>JALT CALL Journal</em> 11 (1).</p>
</div>
<div id="ref-Kaplan2014">
<p>Kaplan, J. J., K. C. Haudek, M. Ha, N. Rogness, and D. G. Fisher. 2014. “Using Lexical Analysis Software to Assess Student Writing in Statistics.” <em>Technology Innovations in Statistics Education</em> 8.</p>
</div>
<div id="ref-Perelman2013">
<p>Perelman, L. 2013. “Critique (Ver. 3.4) of Mark d. Shermis and Ben Hammer, Contrasting State-of-the-Art Automated Scoring of Essays: Analysis.” <em>Critique (Ver. 3.4) of Mark D. Shermis and Ben Hammer, Contrasting State-of-the-Art Automated Scoring of Essays: Analysis</em>.</p>
</div>
<div id="ref-Ruegg2015">
<p>Ruegg, R. 2015. “Differences in the Uptake of Peer and Teacher Feedback.” <em>RELC Journal</em> 46 (2): 131–45.</p>
</div>
<div id="ref-Shermis2010">
<p>Shermis, M. D., J. Burstein, D. Higgins, and K. Zechner. 2010. “Automated Essay Scoring: Writing Assessment and Instruction.” <em>Automated Essay Scoring: Writing Assessment and Instruction</em> 4: 20–26.</p>
</div>
<div id="ref-Urban-Lurain2015">
<p>Urban-Lurain, M., M. M. Cooper, K. C. Haudek, J. J. Kaplan, J. K. Knight, and P. P. Lemons. 2015. “Expanding a National Network for Automated Analysis of Constructed Response Assessments to Reveal Student Thinking in Stem.” <em>Computers in Education Journal</em> 6: 65–81.</p>
</div>
<div id="ref-Weston2015">
<p>Weston, M., K. C. Haudek, L. Prevost, M. Urban-Lurain, and J. Merrill. 2015. “Examining the Impact of Question Surface Features on Students’ Answers to Constructed-Response Questions on Photosynthesis.” <em>CBE - Life Sciences Education</em> 14. doi:<a href="https://doi.org/10.1187/cbe.14-07-0110">10.1187/cbe.14-07-0110</a>.</p>
</div>
</div>
</div>
</div>

<p></p>
<hr>
<p>Copyright &copy; 2019 A. Daniel Johnson. All rights reserved.</p>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
